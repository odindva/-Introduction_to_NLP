{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9947c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn import model_selection, preprocessing, linear_model\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from nltk.util import ngrams\n",
    "import gensim.downloader as api\n",
    "\n",
    "import string\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "import annoy\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04965139",
   "metadata": {},
   "source": [
    "1. Создайте мешок слов с помощью\n",
    "sklearn.feature_extraction.text.CountVectorizer.fit_transform(). Применим его к 'tweet_stemmed'\n",
    "и 'tweet_lemmatized' отдельно.\n",
    "\n",
    "● Игнорируем слова, частота которых в документе строго превышает порог 0.9 с\n",
    "помощью max_df.\n",
    "\n",
    "● Ограничим количество слов, попадающий в мешок, с помощью max_features =\n",
    "1000.\n",
    "\n",
    "● Исключим стоп-слова с помощью stop_words='english'.\n",
    "\n",
    "● Отобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с\n",
    "помощью CountVectorizer.get_feature_names()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b421f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "      <td>[when, father, is, dysfunct, and, is, so, self...</td>\n",
       "      <td>[when, father, be, dysfunctional, and, be, so,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
       "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "      <td>[thank, for, lyft, credit, can, not, use, caus...</td>\n",
       "      <td>[thank, for, lyft, credit, can, not, use, caus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>[bihday, your, majesti]</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model love you take with you all the time in ur</td>\n",
       "      <td>[model, love, you, take, with, you, all, the, ...</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, you, take, with, you, all, the, ...</td>\n",
       "      <td>[model, love, you, take, with, you, all, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "      <td>[factsguid, societi, now, motiv]</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49154</th>\n",
       "      <td>49155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thought factory left right polarisation trump ...</td>\n",
       "      <td>[thought, factory, left, right, polarisation, ...</td>\n",
       "      <td>[thought, factory, left, right, polarisation, ...</td>\n",
       "      <td>[thought, factori, left, right, polaris, trump...</td>\n",
       "      <td>[think, factory, leave, right, polarisation, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49155</th>\n",
       "      <td>49156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>feeling like mermaid hairflip neverready forma...</td>\n",
       "      <td>[feeling, like, mermaid, hairflip, neverready,...</td>\n",
       "      <td>[feeling, like, mermaid, hairflip, neverready,...</td>\n",
       "      <td>[feel, like, mermaid, hairflip, neverreadi, fo...</td>\n",
       "      <td>[feel, like, mermaid, hairflip, neverready, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49156</th>\n",
       "      <td>49157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hillary campaigned today in ohio omg used word...</td>\n",
       "      <td>[hillary, campaigned, today, in, ohio, omg, us...</td>\n",
       "      <td>[hillary, campaigned, today, ohio, omg, used, ...</td>\n",
       "      <td>[hillari, campaign, today, in, ohio, omg, use,...</td>\n",
       "      <td>[hillary, campaign, today, in, ohio, omg, use,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49157</th>\n",
       "      <td>49158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>happy at work conference right mindset leads t...</td>\n",
       "      <td>[happy, at, work, conference, right, mindset, ...</td>\n",
       "      <td>[happy, work, conference, right, mindset, lead...</td>\n",
       "      <td>[happi, at, work, confer, right, mindset, lead...</td>\n",
       "      <td>[happy, at, work, conference, right, mindset, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49158</th>\n",
       "      <td>49159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my song so glad free download shoegaze newmusi...</td>\n",
       "      <td>[my, song, so, glad, free, download, shoegaze,...</td>\n",
       "      <td>[song, glad, free, download, shoegaze, newmusi...</td>\n",
       "      <td>[my, song, so, glad, free, download, shoegaz, ...</td>\n",
       "      <td>[my, song, so, glad, free, download, shoegaze,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49159 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet  \\\n",
       "0          1    0.0  when father is dysfunctional and is so selfish...   \n",
       "1          2    0.0  thanks for lyft credit cannot use cause they d...   \n",
       "2          3    0.0                                bihday your majesty   \n",
       "3          4    0.0    model love you take with you all the time in ur   \n",
       "4          5    0.0                  factsguide society now motivation   \n",
       "...      ...    ...                                                ...   \n",
       "49154  49155    NaN  thought factory left right polarisation trump ...   \n",
       "49155  49156    NaN  feeling like mermaid hairflip neverready forma...   \n",
       "49156  49157    NaN  hillary campaigned today in ohio omg used word...   \n",
       "49157  49158    NaN  happy at work conference right mindset leads t...   \n",
       "49158  49159    NaN  my song so glad free download shoegaze newmusi...   \n",
       "\n",
       "                                             tweet_token  \\\n",
       "0      [when, father, is, dysfunctional, and, is, so,...   \n",
       "1      [thanks, for, lyft, credit, can, not, use, cau...   \n",
       "2                                [bihday, your, majesty]   \n",
       "3      [model, love, you, take, with, you, all, the, ...   \n",
       "4                 [factsguide, society, now, motivation]   \n",
       "...                                                  ...   \n",
       "49154  [thought, factory, left, right, polarisation, ...   \n",
       "49155  [feeling, like, mermaid, hairflip, neverready,...   \n",
       "49156  [hillary, campaigned, today, in, ohio, omg, us...   \n",
       "49157  [happy, at, work, conference, right, mindset, ...   \n",
       "49158  [my, song, so, glad, free, download, shoegaze,...   \n",
       "\n",
       "                                    tweet_token_filtered  \\\n",
       "0      [father, dysfunctional, selfish, drags, kids, ...   \n",
       "1      [thanks, lyft, credit, use, cause, offer, whee...   \n",
       "2                                      [bihday, majesty]   \n",
       "3                          [model, love, take, time, ur]   \n",
       "4                      [factsguide, society, motivation]   \n",
       "...                                                  ...   \n",
       "49154  [thought, factory, left, right, polarisation, ...   \n",
       "49155  [feeling, like, mermaid, hairflip, neverready,...   \n",
       "49156  [hillary, campaigned, today, ohio, omg, used, ...   \n",
       "49157  [happy, work, conference, right, mindset, lead...   \n",
       "49158  [song, glad, free, download, shoegaze, newmusi...   \n",
       "\n",
       "                                           tweet_stemmed  \\\n",
       "0      [when, father, is, dysfunct, and, is, so, self...   \n",
       "1      [thank, for, lyft, credit, can, not, use, caus...   \n",
       "2                                [bihday, your, majesti]   \n",
       "3      [model, love, you, take, with, you, all, the, ...   \n",
       "4                       [factsguid, societi, now, motiv]   \n",
       "...                                                  ...   \n",
       "49154  [thought, factori, left, right, polaris, trump...   \n",
       "49155  [feel, like, mermaid, hairflip, neverreadi, fo...   \n",
       "49156  [hillari, campaign, today, in, ohio, omg, use,...   \n",
       "49157  [happi, at, work, confer, right, mindset, lead...   \n",
       "49158  [my, song, so, glad, free, download, shoegaz, ...   \n",
       "\n",
       "                                        tweet_lemmatized  \n",
       "0      [when, father, be, dysfunctional, and, be, so,...  \n",
       "1      [thank, for, lyft, credit, can, not, use, caus...  \n",
       "2                                [bihday, your, majesty]  \n",
       "3      [model, love, you, take, with, you, all, the, ...  \n",
       "4                 [factsguide, society, now, motivation]  \n",
       "...                                                  ...  \n",
       "49154  [think, factory, leave, right, polarisation, t...  \n",
       "49155  [feel, like, mermaid, hairflip, neverready, fo...  \n",
       "49156  [hillary, campaign, today, in, ohio, omg, use,...  \n",
       "49157  [happy, at, work, conference, right, mindset, ...  \n",
       "49158  [my, song, so, glad, free, download, shoegaze,...  \n",
       "\n",
       "[49159 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df = pd.read_pickle('combine_df.pkl')\n",
    "combine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9e5dfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listmerge(lsts):\n",
    "    res=[]\n",
    "    for lst in lsts:\n",
    "      res.extend(lst)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e3281f",
   "metadata": {},
   "source": [
    "Надеюсь, я правильно понял, что нужно объединить корпус"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d053378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['when',\n",
       " 'father',\n",
       " 'is',\n",
       " 'dysfunct',\n",
       " 'and',\n",
       " 'is',\n",
       " 'so',\n",
       " 'selfish',\n",
       " 'he',\n",
       " 'drag',\n",
       " 'hi',\n",
       " 'kid',\n",
       " 'into',\n",
       " 'hi',\n",
       " 'dysfunct',\n",
       " 'run',\n",
       " 'thank',\n",
       " 'for',\n",
       " 'lyft',\n",
       " 'credit',\n",
       " 'can',\n",
       " 'not',\n",
       " 'use',\n",
       " 'caus',\n",
       " 'they',\n",
       " 'do',\n",
       " 'not',\n",
       " 'offer',\n",
       " 'wheelchair',\n",
       " 'van',\n",
       " 'in',\n",
       " 'pdx',\n",
       " 'disapoint',\n",
       " 'getthank',\n",
       " 'bihday',\n",
       " 'your',\n",
       " 'majesti',\n",
       " 'model',\n",
       " 'love',\n",
       " 'you',\n",
       " 'take',\n",
       " 'with',\n",
       " 'you',\n",
       " 'all',\n",
       " 'the',\n",
       " 'time',\n",
       " 'in',\n",
       " 'ur',\n",
       " 'factsguid',\n",
       " 'societi',\n",
       " 'now',\n",
       " 'motiv',\n",
       " 'huge',\n",
       " 'fan',\n",
       " 'fare',\n",
       " 'and',\n",
       " 'big',\n",
       " 'talk',\n",
       " 'befor',\n",
       " 'they',\n",
       " 'leav',\n",
       " 'chao',\n",
       " 'and',\n",
       " 'pay',\n",
       " 'disput',\n",
       " 'when',\n",
       " 'they',\n",
       " 'get',\n",
       " 'there',\n",
       " 'allshowandnogo',\n",
       " 'camp',\n",
       " 'tomorrow',\n",
       " 'danni',\n",
       " 'the',\n",
       " 'next',\n",
       " 'school',\n",
       " 'year',\n",
       " 'is',\n",
       " 'the',\n",
       " 'year',\n",
       " 'for',\n",
       " 'exam',\n",
       " 'can',\n",
       " 'not',\n",
       " 'think',\n",
       " 'about',\n",
       " 'that',\n",
       " 'school',\n",
       " 'exam',\n",
       " 'hate',\n",
       " 'imagin',\n",
       " 'actorslif',\n",
       " 'revolutionschool',\n",
       " 'girl',\n",
       " 'we',\n",
       " 'won',\n",
       " 'love',\n",
       " 'the',\n",
       " 'land',\n",
       " 'allin',\n",
       " 'cav',\n",
       " 'champion',\n",
       " 'cleveland',\n",
       " 'clevelandcavali',\n",
       " 'welcom',\n",
       " 'here',\n",
       " 'am',\n",
       " 'it',\n",
       " 'ha',\n",
       " 'it',\n",
       " 'is',\n",
       " 'so',\n",
       " 'gr',\n",
       " 'ireland',\n",
       " 'consum',\n",
       " 'price',\n",
       " 'index',\n",
       " 'mom',\n",
       " 'climb',\n",
       " 'from',\n",
       " 'previou',\n",
       " 'to',\n",
       " 'in',\n",
       " 'may',\n",
       " 'blog',\n",
       " 'silver',\n",
       " 'gold',\n",
       " 'forex',\n",
       " 'we',\n",
       " 'are',\n",
       " 'so',\n",
       " 'selfish',\n",
       " 'orlando',\n",
       " 'standwithorlando',\n",
       " 'pulseshoot',\n",
       " 'orlandoshoot',\n",
       " 'biggerproblem',\n",
       " 'selfish',\n",
       " 'heabreak',\n",
       " 'valu',\n",
       " 'love',\n",
       " 'get',\n",
       " 'to',\n",
       " 'see',\n",
       " 'my',\n",
       " 'daddi',\n",
       " 'today',\n",
       " 'day',\n",
       " 'gettingf',\n",
       " 'cnn',\n",
       " 'call',\n",
       " 'michigan',\n",
       " 'middl',\n",
       " 'school',\n",
       " 'build',\n",
       " 'the',\n",
       " 'wall',\n",
       " 'chant',\n",
       " 'tcot',\n",
       " 'no',\n",
       " 'comment',\n",
       " 'in',\n",
       " 'australia',\n",
       " 'opkillingbay',\n",
       " 'seashepherd',\n",
       " 'helpcovedolphin',\n",
       " 'thecov',\n",
       " 'helpcovedolphin',\n",
       " 'ouch',\n",
       " 'junior',\n",
       " 'is',\n",
       " 'angri',\n",
       " 'got',\n",
       " 'junior',\n",
       " 'yugyoem',\n",
       " 'omg',\n",
       " 'am',\n",
       " 'thank',\n",
       " 'for',\n",
       " 'have',\n",
       " 'paner',\n",
       " 'thank',\n",
       " 'posit',\n",
       " 'retweet',\n",
       " 'if',\n",
       " 'you',\n",
       " 'agre',\n",
       " 'it',\n",
       " 'friday',\n",
       " 'smile',\n",
       " 'all',\n",
       " 'around',\n",
       " 'via',\n",
       " 'ig',\n",
       " 'user',\n",
       " 'cooki',\n",
       " 'make',\n",
       " 'peopl',\n",
       " 'as',\n",
       " 'we',\n",
       " 'all',\n",
       " 'know',\n",
       " 'essenti',\n",
       " 'oil',\n",
       " 'are',\n",
       " 'not',\n",
       " 'made',\n",
       " 'of',\n",
       " 'chemic',\n",
       " 'euro',\n",
       " 'peopl',\n",
       " 'blame',\n",
       " 'ha',\n",
       " 'for',\n",
       " 'conced',\n",
       " 'goal',\n",
       " 'wa',\n",
       " 'it',\n",
       " 'fat',\n",
       " 'rooney',\n",
       " 'who',\n",
       " 'gave',\n",
       " 'away',\n",
       " 'free',\n",
       " 'kick',\n",
       " 'know',\n",
       " 'bale',\n",
       " 'can',\n",
       " 'hit',\n",
       " 'them',\n",
       " 'from',\n",
       " 'there',\n",
       " 'sad',\n",
       " 'littl',\n",
       " 'dude',\n",
       " 'badday',\n",
       " 'coneofsham',\n",
       " 'cat',\n",
       " 'piss',\n",
       " 'funni',\n",
       " 'laugh',\n",
       " 'product',\n",
       " 'of',\n",
       " 'the',\n",
       " 'day',\n",
       " 'happi',\n",
       " 'man',\n",
       " 'wine',\n",
       " 'tool',\n",
       " 'who',\n",
       " 'ha',\n",
       " 'who',\n",
       " 'is',\n",
       " 'it',\n",
       " 'ha',\n",
       " 'it',\n",
       " 'is',\n",
       " 'the',\n",
       " 'weekend',\n",
       " 'time',\n",
       " 'to',\n",
       " 'open',\n",
       " 'up',\n",
       " 'drink',\n",
       " 'up',\n",
       " 'lumpi',\n",
       " 'say',\n",
       " 'am',\n",
       " 'prove',\n",
       " 'it',\n",
       " 'lumpi',\n",
       " 'tgif',\n",
       " 'ff',\n",
       " 'to',\n",
       " 'my',\n",
       " 'gamedev',\n",
       " 'indiedev',\n",
       " 'indiegamedev',\n",
       " 'squad',\n",
       " 'beauti',\n",
       " 'sign',\n",
       " 'by',\n",
       " 'vendor',\n",
       " 'for',\n",
       " 'upsideofflorida',\n",
       " 'shopalyssa',\n",
       " 'love',\n",
       " 'all',\n",
       " 'smile',\n",
       " 'when',\n",
       " 'media',\n",
       " 'is',\n",
       " 'pressconfer',\n",
       " 'in',\n",
       " 'antalya',\n",
       " 'turkey',\n",
       " 'sunday',\n",
       " 'throwback',\n",
       " 'love',\n",
       " 'we',\n",
       " 'had',\n",
       " 'great',\n",
       " 'panel',\n",
       " 'on',\n",
       " 'the',\n",
       " 'mediat',\n",
       " 'of',\n",
       " 'the',\n",
       " 'public',\n",
       " 'servic',\n",
       " 'ica',\n",
       " 'happi',\n",
       " 'father',\n",
       " 'day',\n",
       " 'peopl',\n",
       " 'went',\n",
       " 'to',\n",
       " 'nightclub',\n",
       " 'to',\n",
       " 'have',\n",
       " 'good',\n",
       " 'night',\n",
       " 'and',\n",
       " 'man',\n",
       " 'action',\n",
       " 'mean',\n",
       " 'those',\n",
       " 'peopl',\n",
       " 'are',\n",
       " 'lost',\n",
       " 'to',\n",
       " 'their',\n",
       " 'famili',\n",
       " 'forev',\n",
       " 'rip',\n",
       " 'orlando',\n",
       " 'have',\n",
       " 'never',\n",
       " 'had',\n",
       " 'chanc',\n",
       " 'to',\n",
       " 'vote',\n",
       " 'for',\n",
       " 'presidenti',\n",
       " 'candid',\n",
       " 'wa',\n",
       " 'excit',\n",
       " 'about',\n",
       " 'and',\n",
       " 'thi',\n",
       " 'cycl',\n",
       " 'look',\n",
       " 'to',\n",
       " 'be',\n",
       " 'no',\n",
       " 'differ',\n",
       " 'alohafriday',\n",
       " 'time',\n",
       " 'doe',\n",
       " 'not',\n",
       " 'exist',\n",
       " 'positivevib',\n",
       " 'hawaiian',\n",
       " 'rip',\n",
       " 'to',\n",
       " 'the',\n",
       " 'fellow',\n",
       " 'nohern',\n",
       " 'ireland',\n",
       " 'fan',\n",
       " 'who',\n",
       " 'sadley',\n",
       " 'pass',\n",
       " 'away',\n",
       " 'tonight',\n",
       " 'gawa',\n",
       " 'forev',\n",
       " 'sing',\n",
       " 'and',\n",
       " 'cheer',\n",
       " 'on',\n",
       " 'fire',\n",
       " 'it',\n",
       " 'wa',\n",
       " 'hard',\n",
       " 'monday',\n",
       " 'due',\n",
       " 'to',\n",
       " 'cloudi',\n",
       " 'weather',\n",
       " 'disabl',\n",
       " 'oxygen',\n",
       " 'product',\n",
       " 'for',\n",
       " 'today',\n",
       " 'goodnight',\n",
       " 'badmonday',\n",
       " 'it',\n",
       " 'ha',\n",
       " 'it',\n",
       " 'is',\n",
       " 'unbeliev',\n",
       " 'that',\n",
       " 'in',\n",
       " 'the',\n",
       " 'st',\n",
       " 'centuri',\n",
       " 'we',\n",
       " 'had',\n",
       " 'we',\n",
       " 'would',\n",
       " 'need',\n",
       " 'someth',\n",
       " 'like',\n",
       " 'thi',\n",
       " 'again',\n",
       " 'neverump',\n",
       " 'xenophobia',\n",
       " 'taylorswift',\n",
       " 'bull',\n",
       " 'up',\n",
       " 'you',\n",
       " 'will',\n",
       " 'domin',\n",
       " 'your',\n",
       " 'bull',\n",
       " 'and',\n",
       " 'you',\n",
       " 'will',\n",
       " 'direct',\n",
       " 'it',\n",
       " 'whatev',\n",
       " 'you',\n",
       " 'want',\n",
       " 'it',\n",
       " 'to',\n",
       " 'do',\n",
       " 'morn',\n",
       " 'travelingram',\n",
       " 'dalat',\n",
       " 'ripinkylif',\n",
       " 'onc',\n",
       " 'more',\n",
       " 'onli',\n",
       " 'one',\n",
       " 'word',\n",
       " 'tell',\n",
       " 'it',\n",
       " 'all',\n",
       " 'photoshop',\n",
       " 'enoughisenough',\n",
       " 'dontphotoshopeveryth',\n",
       " 'wheresallthenaturalphoto',\n",
       " 'oh',\n",
       " 'cedarpoint',\n",
       " 'wait',\n",
       " 'hour',\n",
       " 'in',\n",
       " 'the',\n",
       " 'valravn',\n",
       " 'line',\n",
       " 'and',\n",
       " 'it',\n",
       " 'stop',\n",
       " 'work',\n",
       " 'we',\n",
       " 'were',\n",
       " 'so',\n",
       " 'close',\n",
       " 'am',\n",
       " 'thank',\n",
       " 'for',\n",
       " 'sunshin',\n",
       " 'thank',\n",
       " 'posit',\n",
       " 'when',\n",
       " 'you',\n",
       " 'final',\n",
       " 'finish',\n",
       " 'book',\n",
       " 'you',\n",
       " 'have',\n",
       " 'been',\n",
       " 'work',\n",
       " 'on',\n",
       " 'for',\n",
       " 'awhil',\n",
       " 'bookworm',\n",
       " 'ontothenextnovel',\n",
       " 'yup',\n",
       " 'be',\n",
       " 'knick',\n",
       " 'fan',\n",
       " 'is',\n",
       " 'hard',\n",
       " 'so',\n",
       " 'it',\n",
       " 'easier',\n",
       " 'to',\n",
       " 'just',\n",
       " 'be',\n",
       " 'an',\n",
       " 'nba',\n",
       " 'fan',\n",
       " 'when',\n",
       " 'the',\n",
       " 'playoff',\n",
       " 'roll',\n",
       " 'around',\n",
       " 'there',\n",
       " 'is',\n",
       " 'life',\n",
       " 'after',\n",
       " 'social',\n",
       " 'network',\n",
       " 'embrac',\n",
       " 'each',\n",
       " 'day',\n",
       " 'be',\n",
       " 'my',\n",
       " 'mom',\n",
       " 'share',\n",
       " 'the',\n",
       " 'same',\n",
       " 'bihday',\n",
       " 'as',\n",
       " 'bihday',\n",
       " 'snake',\n",
       " 'see',\n",
       " 'you',\n",
       " 'thi',\n",
       " 'weekend',\n",
       " 'love',\n",
       " 'echeveria',\n",
       " 'bloom',\n",
       " 'flower',\n",
       " 'grow',\n",
       " 'garden',\n",
       " 'iphonesia',\n",
       " 'bliss',\n",
       " 'bloom',\n",
       " 'basilicabotanica',\n",
       " 'am',\n",
       " 'amaz',\n",
       " 'am',\n",
       " 'posit',\n",
       " 'affirm',\n",
       " 'model',\n",
       " 'love',\n",
       " 'you',\n",
       " 'take',\n",
       " 'with',\n",
       " 'you',\n",
       " 'all',\n",
       " 'the',\n",
       " 'time',\n",
       " 'in',\n",
       " 'ur',\n",
       " 'whenev',\n",
       " 'im',\n",
       " 'and',\n",
       " 'someth',\n",
       " 'goe',\n",
       " 'wrong',\n",
       " 'feel',\n",
       " 'blue',\n",
       " 'illustr',\n",
       " 'the',\n",
       " 'best',\n",
       " 'pa',\n",
       " 'about',\n",
       " 'life',\n",
       " 'is',\n",
       " 'know',\n",
       " 'who',\n",
       " 'you',\n",
       " 'are',\n",
       " 'abc',\n",
       " 'get',\n",
       " 'readi',\n",
       " 'remov',\n",
       " 'the',\n",
       " 'victum',\n",
       " 'frm',\n",
       " 'pulseclub',\n",
       " 'prayfororlando',\n",
       " 'for',\n",
       " 'her',\n",
       " 'bihday',\n",
       " 'we',\n",
       " 'got',\n",
       " 'her',\n",
       " 'nose',\n",
       " 'job',\n",
       " 'bihday',\n",
       " 'petunia',\n",
       " 'we',\n",
       " 'love',\n",
       " 'you',\n",
       " 'off',\n",
       " 'to',\n",
       " 'concelebr',\n",
       " 'at',\n",
       " 'the',\n",
       " 'albanpilgrimag',\n",
       " 'for',\n",
       " 'the',\n",
       " 'first',\n",
       " 'time',\n",
       " 'let',\n",
       " 'the',\n",
       " 'scum',\n",
       " 'baggeri',\n",
       " 'begin',\n",
       " 'thank',\n",
       " 'you',\n",
       " 'super',\n",
       " 'love',\n",
       " 'it',\n",
       " 'zpamdelacruz',\n",
       " 'wed',\n",
       " 'dolor',\n",
       " 'capa',\n",
       " 'tarlac',\n",
       " 'scourg',\n",
       " 'on',\n",
       " 'those',\n",
       " 'play',\n",
       " 'baroqu',\n",
       " 'piec',\n",
       " 'on',\n",
       " 'piano',\n",
       " 'beyond',\n",
       " 'belief',\n",
       " 'let',\n",
       " 'fight',\n",
       " 'against',\n",
       " 'love',\n",
       " 'peac',\n",
       " 'happi',\n",
       " 'father',\n",
       " 'day',\n",
       " 'mr',\n",
       " 'rayo',\n",
       " 'video',\n",
       " 'father',\n",
       " 'day',\n",
       " 'rayo',\n",
       " 'world',\n",
       " 'hotvideo',\n",
       " 'video',\n",
       " 'ascot',\n",
       " 'time',\n",
       " 'with',\n",
       " 'thi',\n",
       " 'babe',\n",
       " 'ascot',\n",
       " 'fashion',\n",
       " 'monochrom',\n",
       " 'style',\n",
       " 'instahappyday',\n",
       " 'the',\n",
       " 'weekend',\n",
       " 'is',\n",
       " 'here',\n",
       " 'selfi',\n",
       " 'yolo',\n",
       " 'xoxo',\n",
       " 'like',\n",
       " 'like',\n",
       " 'happi',\n",
       " 'at',\n",
       " 'work',\n",
       " 'confer',\n",
       " 'right',\n",
       " 'mindset',\n",
       " 'lead',\n",
       " 'to',\n",
       " 'cultur',\n",
       " 'of',\n",
       " 'develop',\n",
       " 'organ',\n",
       " 'work',\n",
       " 'mindset',\n",
       " 'christina',\n",
       " 'grimmi',\n",
       " 'last',\n",
       " 'perform',\n",
       " 'befor',\n",
       " 'be',\n",
       " 'shot',\n",
       " 'via',\n",
       " 'christinarip',\n",
       " 'voic',\n",
       " 'christinagrimmi',\n",
       " 'we',\n",
       " 'are',\n",
       " 'readi',\n",
       " 'to',\n",
       " 'danc',\n",
       " 'roar',\n",
       " 'preschool',\n",
       " 'student',\n",
       " 'proud',\n",
       " 'you',\n",
       " 'have',\n",
       " 'realli',\n",
       " 'hu',\n",
       " 'my',\n",
       " 'feel',\n",
       " 'sad',\n",
       " 'my',\n",
       " 'wife',\n",
       " 'whom',\n",
       " 'ador',\n",
       " 'had',\n",
       " 'to',\n",
       " 'miss',\n",
       " 'your',\n",
       " 'poland',\n",
       " 'show',\n",
       " 'becaus',\n",
       " 'she',\n",
       " 'had',\n",
       " 'surgeri',\n",
       " 'her',\n",
       " 'name',\n",
       " 'is',\n",
       " 'bridget',\n",
       " 'she',\n",
       " 'ha',\n",
       " 'she',\n",
       " 'is',\n",
       " 'my',\n",
       " 'everyth',\n",
       " 'am',\n",
       " 'so',\n",
       " 'jealou',\n",
       " 'of',\n",
       " 'you',\n",
       " 'right',\n",
       " 'now',\n",
       " 'chatiado',\n",
       " 'celebr',\n",
       " 'everi',\n",
       " 'man',\n",
       " 'that',\n",
       " 'ha',\n",
       " 'play',\n",
       " 'it',\n",
       " 'ha',\n",
       " 'it',\n",
       " 'is',\n",
       " 'fatherli',\n",
       " 'role',\n",
       " 'father',\n",
       " 'day',\n",
       " 'am',\n",
       " 'sure',\n",
       " 'they',\n",
       " 'are',\n",
       " 'just',\n",
       " 'as',\n",
       " 'happi',\n",
       " 'hour',\n",
       " 'the',\n",
       " 'white',\n",
       " 'establish',\n",
       " 'can',\n",
       " 'not',\n",
       " 'have',\n",
       " 'blk',\n",
       " 'folx',\n",
       " 'run',\n",
       " 'around',\n",
       " 'love',\n",
       " 'themselv',\n",
       " 'and',\n",
       " 'promot',\n",
       " 'our',\n",
       " 'great',\n",
       " 'good',\n",
       " 'morn',\n",
       " 'the',\n",
       " 'journey',\n",
       " 'begin',\n",
       " 'travel',\n",
       " 'yeah',\n",
       " 'thejourneybegin',\n",
       " 'hello',\n",
       " 'if',\n",
       " 'you',\n",
       " 'luv',\n",
       " 'hottweet',\n",
       " 'like',\n",
       " 'thi',\n",
       " 'from',\n",
       " 'venusexchang',\n",
       " 'our',\n",
       " 'new',\n",
       " 'brochur',\n",
       " 'have',\n",
       " 'arriv',\n",
       " 'how',\n",
       " 'excit',\n",
       " 'awork',\n",
       " 'solut',\n",
       " 'so',\n",
       " 'much',\n",
       " 'stuff',\n",
       " 'happen',\n",
       " 'in',\n",
       " 'florida',\n",
       " 'first',\n",
       " 'orlando',\n",
       " 'shoot',\n",
       " 'and',\n",
       " 'now',\n",
       " 'disneygatorattack',\n",
       " 'on',\n",
       " 'two',\n",
       " 'year',\n",
       " 'old',\n",
       " 'kid',\n",
       " 'ferrari',\n",
       " 'will',\n",
       " 'do',\n",
       " 'it',\n",
       " 'for',\n",
       " 'the',\n",
       " 'sake',\n",
       " 'of',\n",
       " 'the',\n",
       " 'championship',\n",
       " 'thi',\n",
       " 'gp',\n",
       " 'is',\n",
       " 'clearli',\n",
       " 'turn',\n",
       " 'point',\n",
       " 'rb',\n",
       " 'ferrari',\n",
       " 'merc',\n",
       " 'ace',\n",
       " 'my',\n",
       " 'first',\n",
       " 'test',\n",
       " 'proud',\n",
       " 'seek',\n",
       " 'probe',\n",
       " 'into',\n",
       " 'udtapunjab',\n",
       " 'leak',\n",
       " 'point',\n",
       " 'finger',\n",
       " 'at',\n",
       " 'amarind',\n",
       " 'aap',\n",
       " 'wrap',\n",
       " 'up',\n",
       " 'senseaboutmath',\n",
       " 'th',\n",
       " 'hey',\n",
       " 'white',\n",
       " 'peopl',\n",
       " 'you',\n",
       " 'can',\n",
       " 'call',\n",
       " 'peopl',\n",
       " 'white',\n",
       " 'by',\n",
       " 'race',\n",
       " 'ident',\n",
       " 'med',\n",
       " 'you',\n",
       " 'might',\n",
       " 'be',\n",
       " 'just',\n",
       " 'have',\n",
       " 'not',\n",
       " 'shown',\n",
       " 'here',\n",
       " 'today',\n",
       " 'regurgit',\n",
       " 'talk',\n",
       " 'point',\n",
       " 'and',\n",
       " 'name',\n",
       " 'call',\n",
       " 'sometim',\n",
       " 'you',\n",
       " 'have',\n",
       " 'to',\n",
       " 'rais',\n",
       " 'few',\n",
       " 'brow',\n",
       " 'to',\n",
       " 'rais',\n",
       " 'the',\n",
       " 'bar',\n",
       " 'golfstrengthandcondit',\n",
       " 'strong',\n",
       " 'felixfoisgolf',\n",
       " 'about',\n",
       " 'that',\n",
       " 'greathonour',\n",
       " 'careerconvo',\n",
       " 'design',\n",
       " 'innov',\n",
       " 'learn',\n",
       " 'space',\n",
       " 'to',\n",
       " 'includ',\n",
       " 'wateringhol',\n",
       " 'cave',\n",
       " 'mountaintop',\n",
       " 'campfir',\n",
       " 'how',\n",
       " 'the',\n",
       " 'altright',\n",
       " 'use',\n",
       " 'insecur',\n",
       " 'to',\n",
       " 'lure',\n",
       " 'men',\n",
       " 'into',\n",
       " 'whitesupremaci',\n",
       " 'carri',\n",
       " 'gun',\n",
       " 'would',\n",
       " 'not',\n",
       " 'of',\n",
       " 'help',\n",
       " 'if',\n",
       " 'you',\n",
       " 'can',\n",
       " 'not',\n",
       " 'take',\n",
       " 'it',\n",
       " 'in',\n",
       " 'with',\n",
       " 'you',\n",
       " 'gun',\n",
       " 'control',\n",
       " 'will',\n",
       " 'not',\n",
       " 'stop',\n",
       " 'the',\n",
       " 'black',\n",
       " 'market',\n",
       " 'terror',\n",
       " 'will',\n",
       " 'get',\n",
       " 'wors',\n",
       " 'use',\n",
       " 'the',\n",
       " 'power',\n",
       " 'of',\n",
       " 'your',\n",
       " 'mind',\n",
       " 'to',\n",
       " 'heal',\n",
       " 'your',\n",
       " 'bodi',\n",
       " 'altwaystoh',\n",
       " 'healthi',\n",
       " 'peac',\n",
       " 'woohoo',\n",
       " 'just',\n",
       " 'over',\n",
       " 'week',\n",
       " 'to',\n",
       " 'go',\n",
       " 'be',\n",
       " 'in',\n",
       " 'far',\n",
       " 'away',\n",
       " 'place',\n",
       " 'where',\n",
       " 'you',\n",
       " 'have',\n",
       " 'no',\n",
       " 'famili',\n",
       " 'member',\n",
       " 'hu',\n",
       " 'readi',\n",
       " 'to',\n",
       " 'rehears',\n",
       " 'tonight',\n",
       " 'with',\n",
       " 'new',\n",
       " 'music',\n",
       " 'and',\n",
       " 'new',\n",
       " 'video',\n",
       " 'look',\n",
       " 'out',\n",
       " 'for',\n",
       " 'the',\n",
       " 'announc',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_stemmed = listmerge(list(combine_df['tweet_stemmed']))\n",
    "corpus_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a090514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['when',\n",
       " 'father',\n",
       " 'be',\n",
       " 'dysfunctional',\n",
       " 'and',\n",
       " 'be',\n",
       " 'so',\n",
       " 'selfish',\n",
       " 'he',\n",
       " 'drag',\n",
       " 'his',\n",
       " 'kid',\n",
       " 'into',\n",
       " 'his',\n",
       " 'dysfunction',\n",
       " 'run',\n",
       " 'thank',\n",
       " 'for',\n",
       " 'lyft',\n",
       " 'credit',\n",
       " 'can',\n",
       " 'not',\n",
       " 'use',\n",
       " 'cause',\n",
       " 'they',\n",
       " 'do',\n",
       " 'not',\n",
       " 'offer',\n",
       " 'wheelchair',\n",
       " 'vans',\n",
       " 'in',\n",
       " 'pdx',\n",
       " 'disapointed',\n",
       " 'getthanked',\n",
       " 'bihday',\n",
       " 'your',\n",
       " 'majesty',\n",
       " 'model',\n",
       " 'love',\n",
       " 'you',\n",
       " 'take',\n",
       " 'with',\n",
       " 'you',\n",
       " 'all',\n",
       " 'the',\n",
       " 'time',\n",
       " 'in',\n",
       " 'ur',\n",
       " 'factsguide',\n",
       " 'society',\n",
       " 'now',\n",
       " 'motivation',\n",
       " 'huge',\n",
       " 'fan',\n",
       " 'fare',\n",
       " 'and',\n",
       " 'big',\n",
       " 'talk',\n",
       " 'before',\n",
       " 'they',\n",
       " 'leave',\n",
       " 'chaos',\n",
       " 'and',\n",
       " 'pay',\n",
       " 'dispute',\n",
       " 'when',\n",
       " 'they',\n",
       " 'get',\n",
       " 'there',\n",
       " 'allshowandnogo',\n",
       " 'camp',\n",
       " 'tomorrow',\n",
       " 'danny',\n",
       " 'the',\n",
       " 'next',\n",
       " 'school',\n",
       " 'year',\n",
       " 'be',\n",
       " 'the',\n",
       " 'year',\n",
       " 'for',\n",
       " 'exams',\n",
       " 'can',\n",
       " 'not',\n",
       " 'think',\n",
       " 'about',\n",
       " 'that',\n",
       " 'school',\n",
       " 'exams',\n",
       " 'hate',\n",
       " 'imagine',\n",
       " 'actorslife',\n",
       " 'revolutionschool',\n",
       " 'girl',\n",
       " 'we',\n",
       " 'win',\n",
       " 'love',\n",
       " 'the',\n",
       " 'land',\n",
       " 'allin',\n",
       " 'cavs',\n",
       " 'champion',\n",
       " 'cleveland',\n",
       " 'clevelandcavaliers',\n",
       " 'welcome',\n",
       " 'here',\n",
       " 'be',\n",
       " 'it',\n",
       " 'have',\n",
       " 'it',\n",
       " 'be',\n",
       " 'so',\n",
       " 'gr',\n",
       " 'ireland',\n",
       " 'consumer',\n",
       " 'price',\n",
       " 'index',\n",
       " 'mom',\n",
       " 'climb',\n",
       " 'from',\n",
       " 'previous',\n",
       " 'to',\n",
       " 'in',\n",
       " 'may',\n",
       " 'blog',\n",
       " 'silver',\n",
       " 'gold',\n",
       " 'forex',\n",
       " 'we',\n",
       " 'be',\n",
       " 'so',\n",
       " 'selfish',\n",
       " 'orlando',\n",
       " 'standwithorlando',\n",
       " 'pulseshooting',\n",
       " 'orlandoshooting',\n",
       " 'biggerproblems',\n",
       " 'selfish',\n",
       " 'heabreaking',\n",
       " 'value',\n",
       " 'love',\n",
       " 'get',\n",
       " 'to',\n",
       " 'see',\n",
       " 'my',\n",
       " 'daddy',\n",
       " 'today',\n",
       " 'days',\n",
       " 'gettingfed',\n",
       " 'cnn',\n",
       " 'call',\n",
       " 'michigan',\n",
       " 'middle',\n",
       " 'school',\n",
       " 'build',\n",
       " 'the',\n",
       " 'wall',\n",
       " 'chant',\n",
       " 'tcot',\n",
       " 'no',\n",
       " 'comment',\n",
       " 'in',\n",
       " 'australia',\n",
       " 'opkillingbay',\n",
       " 'seashepherd',\n",
       " 'helpcovedolphins',\n",
       " 'thecove',\n",
       " 'helpcovedolphins',\n",
       " 'ouch',\n",
       " 'junior',\n",
       " 'be',\n",
       " 'angry',\n",
       " 'get',\n",
       " 'junior',\n",
       " 'yugyoem',\n",
       " 'omg',\n",
       " 'be',\n",
       " 'thankful',\n",
       " 'for',\n",
       " 'have',\n",
       " 'paner',\n",
       " 'thankful',\n",
       " 'positive',\n",
       " 'retweet',\n",
       " 'if',\n",
       " 'you',\n",
       " 'agree',\n",
       " 'its',\n",
       " 'friday',\n",
       " 'smile',\n",
       " 'all',\n",
       " 'around',\n",
       " 'via',\n",
       " 'ig',\n",
       " 'user',\n",
       " 'cookies',\n",
       " 'make',\n",
       " 'people',\n",
       " 'as',\n",
       " 'we',\n",
       " 'all',\n",
       " 'know',\n",
       " 'essential',\n",
       " 'oil',\n",
       " 'be',\n",
       " 'not',\n",
       " 'make',\n",
       " 'of',\n",
       " 'chemicals',\n",
       " 'euro',\n",
       " 'people',\n",
       " 'blame',\n",
       " 'ha',\n",
       " 'for',\n",
       " 'concede',\n",
       " 'goal',\n",
       " 'be',\n",
       " 'it',\n",
       " 'fat',\n",
       " 'rooney',\n",
       " 'who',\n",
       " 'give',\n",
       " 'away',\n",
       " 'free',\n",
       " 'kick',\n",
       " 'know',\n",
       " 'bale',\n",
       " 'can',\n",
       " 'hit',\n",
       " 'them',\n",
       " 'from',\n",
       " 'there',\n",
       " 'sad',\n",
       " 'little',\n",
       " 'dude',\n",
       " 'badday',\n",
       " 'coneofshame',\n",
       " 'cat',\n",
       " 'piss',\n",
       " 'funny',\n",
       " 'laugh',\n",
       " 'product',\n",
       " 'of',\n",
       " 'the',\n",
       " 'day',\n",
       " 'happy',\n",
       " 'man',\n",
       " 'wine',\n",
       " 'tool',\n",
       " 'who',\n",
       " 'have',\n",
       " 'who',\n",
       " 'be',\n",
       " 'it',\n",
       " 'have',\n",
       " 'it',\n",
       " 'be',\n",
       " 'the',\n",
       " 'weekend',\n",
       " 'time',\n",
       " 'to',\n",
       " 'open',\n",
       " 'up',\n",
       " 'drink',\n",
       " 'up',\n",
       " 'lumpy',\n",
       " 'say',\n",
       " 'be',\n",
       " 'prove',\n",
       " 'it',\n",
       " 'lumpy',\n",
       " 'tgif',\n",
       " 'ff',\n",
       " 'to',\n",
       " 'my',\n",
       " 'gamedev',\n",
       " 'indiedev',\n",
       " 'indiegamedev',\n",
       " 'squad',\n",
       " 'beautiful',\n",
       " 'sign',\n",
       " 'by',\n",
       " 'vendor',\n",
       " 'for',\n",
       " 'upsideofflorida',\n",
       " 'shopalyssas',\n",
       " 'love',\n",
       " 'all',\n",
       " 'smile',\n",
       " 'when',\n",
       " 'media',\n",
       " 'be',\n",
       " 'pressconference',\n",
       " 'in',\n",
       " 'antalya',\n",
       " 'turkey',\n",
       " 'sunday',\n",
       " 'throwback',\n",
       " 'love',\n",
       " 'we',\n",
       " 'have',\n",
       " 'great',\n",
       " 'panel',\n",
       " 'on',\n",
       " 'the',\n",
       " 'mediatization',\n",
       " 'of',\n",
       " 'the',\n",
       " 'public',\n",
       " 'service',\n",
       " 'ica',\n",
       " 'happy',\n",
       " 'father',\n",
       " 'day',\n",
       " 'people',\n",
       " 'go',\n",
       " 'to',\n",
       " 'nightclub',\n",
       " 'to',\n",
       " 'have',\n",
       " 'good',\n",
       " 'night',\n",
       " 'and',\n",
       " 'man',\n",
       " 'action',\n",
       " 'mean',\n",
       " 'those',\n",
       " 'people',\n",
       " 'be',\n",
       " 'lose',\n",
       " 'to',\n",
       " 'their',\n",
       " 'families',\n",
       " 'forever',\n",
       " 'rip',\n",
       " 'orlando',\n",
       " 'have',\n",
       " 'never',\n",
       " 'have',\n",
       " 'chance',\n",
       " 'to',\n",
       " 'vote',\n",
       " 'for',\n",
       " 'presidential',\n",
       " 'candidate',\n",
       " 'be',\n",
       " 'excite',\n",
       " 'about',\n",
       " 'and',\n",
       " 'this',\n",
       " 'cycle',\n",
       " 'look',\n",
       " 'to',\n",
       " 'be',\n",
       " 'no',\n",
       " 'different',\n",
       " 'alohafriday',\n",
       " 'time',\n",
       " 'do',\n",
       " 'not',\n",
       " 'exist',\n",
       " 'positivevibes',\n",
       " 'hawaiian',\n",
       " 'rip',\n",
       " 'to',\n",
       " 'the',\n",
       " 'fellow',\n",
       " 'nohern',\n",
       " 'ireland',\n",
       " 'fan',\n",
       " 'who',\n",
       " 'sadley',\n",
       " 'pass',\n",
       " 'away',\n",
       " 'tonight',\n",
       " 'gawa',\n",
       " 'forever',\n",
       " 'sing',\n",
       " 'and',\n",
       " 'cheer',\n",
       " 'on',\n",
       " 'fire',\n",
       " 'it',\n",
       " 'be',\n",
       " 'hard',\n",
       " 'monday',\n",
       " 'due',\n",
       " 'to',\n",
       " 'cloudy',\n",
       " 'weather',\n",
       " 'disable',\n",
       " 'oxygen',\n",
       " 'production',\n",
       " 'for',\n",
       " 'today',\n",
       " 'goodnight',\n",
       " 'badmonday',\n",
       " 'it',\n",
       " 'have',\n",
       " 'it',\n",
       " 'be',\n",
       " 'unbelievable',\n",
       " 'that',\n",
       " 'in',\n",
       " 'the',\n",
       " 'st',\n",
       " 'century',\n",
       " 'we',\n",
       " 'have',\n",
       " 'we',\n",
       " 'would',\n",
       " 'need',\n",
       " 'something',\n",
       " 'like',\n",
       " 'this',\n",
       " 'again',\n",
       " 'neverump',\n",
       " 'xenophobia',\n",
       " 'taylorswift',\n",
       " 'bull',\n",
       " 'up',\n",
       " 'you',\n",
       " 'will',\n",
       " 'dominate',\n",
       " 'your',\n",
       " 'bull',\n",
       " 'and',\n",
       " 'you',\n",
       " 'will',\n",
       " 'direct',\n",
       " 'it',\n",
       " 'whatever',\n",
       " 'you',\n",
       " 'want',\n",
       " 'it',\n",
       " 'to',\n",
       " 'do',\n",
       " 'morning',\n",
       " 'travelingram',\n",
       " 'dalat',\n",
       " 'ripinkylife',\n",
       " 'once',\n",
       " 'more',\n",
       " 'only',\n",
       " 'one',\n",
       " 'word',\n",
       " 'tell',\n",
       " 'it',\n",
       " 'all',\n",
       " 'photoshop',\n",
       " 'enoughisenough',\n",
       " 'dontphotoshopeverything',\n",
       " 'wheresallthenaturalphotos',\n",
       " 'oh',\n",
       " 'cedarpoint',\n",
       " 'wait',\n",
       " 'hours',\n",
       " 'in',\n",
       " 'the',\n",
       " 'valravn',\n",
       " 'line',\n",
       " 'and',\n",
       " 'it',\n",
       " 'stop',\n",
       " 'work',\n",
       " 'we',\n",
       " 'be',\n",
       " 'so',\n",
       " 'close',\n",
       " 'be',\n",
       " 'thankful',\n",
       " 'for',\n",
       " 'sunshine',\n",
       " 'thankful',\n",
       " 'positive',\n",
       " 'when',\n",
       " 'you',\n",
       " 'finally',\n",
       " 'finish',\n",
       " 'book',\n",
       " 'you',\n",
       " 'have',\n",
       " 'be',\n",
       " 'work',\n",
       " 'on',\n",
       " 'for',\n",
       " 'awhile',\n",
       " 'bookworm',\n",
       " 'ontothenextnovel',\n",
       " 'yup',\n",
       " 'be',\n",
       " 'knicks',\n",
       " 'fan',\n",
       " 'be',\n",
       " 'hard',\n",
       " 'so',\n",
       " 'its',\n",
       " 'easier',\n",
       " 'to',\n",
       " 'just',\n",
       " 'be',\n",
       " 'an',\n",
       " 'nba',\n",
       " 'fan',\n",
       " 'when',\n",
       " 'the',\n",
       " 'playoffs',\n",
       " 'roll',\n",
       " 'around',\n",
       " 'there',\n",
       " 'be',\n",
       " 'life',\n",
       " 'after',\n",
       " 'social',\n",
       " 'network',\n",
       " 'embrace',\n",
       " 'each',\n",
       " 'day',\n",
       " 'be',\n",
       " 'my',\n",
       " 'mom',\n",
       " 'share',\n",
       " 'the',\n",
       " 'same',\n",
       " 'bihday',\n",
       " 'as',\n",
       " 'bihday',\n",
       " 'snake',\n",
       " 'see',\n",
       " 'you',\n",
       " 'this',\n",
       " 'weekend',\n",
       " 'lovely',\n",
       " 'echeveria',\n",
       " 'bloom',\n",
       " 'flower',\n",
       " 'grow',\n",
       " 'garden',\n",
       " 'iphonesia',\n",
       " 'bliss',\n",
       " 'bloom',\n",
       " 'basilicabotanica',\n",
       " 'be',\n",
       " 'amaze',\n",
       " 'be',\n",
       " 'positive',\n",
       " 'affirmation',\n",
       " 'model',\n",
       " 'love',\n",
       " 'you',\n",
       " 'take',\n",
       " 'with',\n",
       " 'you',\n",
       " 'all',\n",
       " 'the',\n",
       " 'time',\n",
       " 'in',\n",
       " 'ur',\n",
       " 'whenever',\n",
       " 'im',\n",
       " 'and',\n",
       " 'something',\n",
       " 'go',\n",
       " 'wrong',\n",
       " 'feel',\n",
       " 'blue',\n",
       " 'illustration',\n",
       " 'the',\n",
       " 'best',\n",
       " 'pa',\n",
       " 'about',\n",
       " 'life',\n",
       " 'be',\n",
       " 'know',\n",
       " 'who',\n",
       " 'you',\n",
       " 'be',\n",
       " 'abc',\n",
       " 'get',\n",
       " 'ready',\n",
       " 'remove',\n",
       " 'the',\n",
       " 'victums',\n",
       " 'frm',\n",
       " 'pulseclub',\n",
       " 'prayfororlando',\n",
       " 'for',\n",
       " 'her',\n",
       " 'bihday',\n",
       " 'we',\n",
       " 'get',\n",
       " 'her',\n",
       " 'nose',\n",
       " 'job',\n",
       " 'bihday',\n",
       " 'petunia',\n",
       " 'we',\n",
       " 'love',\n",
       " 'you',\n",
       " 'off',\n",
       " 'to',\n",
       " 'concelebrate',\n",
       " 'at',\n",
       " 'the',\n",
       " 'albanpilgrimage',\n",
       " 'for',\n",
       " 'the',\n",
       " 'first',\n",
       " 'time',\n",
       " 'let',\n",
       " 'the',\n",
       " 'scum',\n",
       " 'baggery',\n",
       " 'begin',\n",
       " 'thank',\n",
       " 'you',\n",
       " 'super',\n",
       " 'love',\n",
       " 'it',\n",
       " 'zpamdelacruz',\n",
       " 'wed',\n",
       " 'dolores',\n",
       " 'capas',\n",
       " 'tarlac',\n",
       " 'scourge',\n",
       " 'on',\n",
       " 'those',\n",
       " 'play',\n",
       " 'baroque',\n",
       " 'piece',\n",
       " 'on',\n",
       " 'piano',\n",
       " 'beyond',\n",
       " 'belief',\n",
       " 'let',\n",
       " 'fight',\n",
       " 'against',\n",
       " 'love',\n",
       " 'peace',\n",
       " 'happy',\n",
       " 'father',\n",
       " 'day',\n",
       " 'mr',\n",
       " 'rayos',\n",
       " 'video',\n",
       " 'father',\n",
       " 'day',\n",
       " 'rayos',\n",
       " 'world',\n",
       " 'hotvideo',\n",
       " 'videos',\n",
       " 'ascot',\n",
       " 'time',\n",
       " 'with',\n",
       " 'this',\n",
       " 'babe',\n",
       " 'ascot',\n",
       " 'fashion',\n",
       " 'monochrome',\n",
       " 'style',\n",
       " 'instahappyday',\n",
       " 'the',\n",
       " 'weekend',\n",
       " 'be',\n",
       " 'here',\n",
       " 'selfie',\n",
       " 'yolo',\n",
       " 'xoxo',\n",
       " 'like',\n",
       " 'like',\n",
       " 'happy',\n",
       " 'at',\n",
       " 'work',\n",
       " 'conference',\n",
       " 'right',\n",
       " 'mindset',\n",
       " 'lead',\n",
       " 'to',\n",
       " 'culture',\n",
       " 'of',\n",
       " 'development',\n",
       " 'organizations',\n",
       " 'work',\n",
       " 'mindset',\n",
       " 'christina',\n",
       " 'grimmie',\n",
       " 'last',\n",
       " 'performance',\n",
       " 'before',\n",
       " 'be',\n",
       " 'shoot',\n",
       " 'via',\n",
       " 'christinarip',\n",
       " 'voice',\n",
       " 'christinagrimmie',\n",
       " 'we',\n",
       " 'be',\n",
       " 'ready',\n",
       " 'to',\n",
       " 'dance',\n",
       " 'roar',\n",
       " 'preschoolers',\n",
       " 'students',\n",
       " 'proud',\n",
       " 'you',\n",
       " 'have',\n",
       " 'really',\n",
       " 'hu',\n",
       " 'my',\n",
       " 'feel',\n",
       " 'sad',\n",
       " 'my',\n",
       " 'wife',\n",
       " 'whom',\n",
       " 'adore',\n",
       " 'have',\n",
       " 'to',\n",
       " 'miss',\n",
       " 'your',\n",
       " 'poland',\n",
       " 'show',\n",
       " 'because',\n",
       " 'she',\n",
       " 'have',\n",
       " 'surgery',\n",
       " 'her',\n",
       " 'name',\n",
       " 'be',\n",
       " 'bridget',\n",
       " 'she',\n",
       " 'have',\n",
       " 'she',\n",
       " 'be',\n",
       " 'my',\n",
       " 'everything',\n",
       " 'be',\n",
       " 'so',\n",
       " 'jealous',\n",
       " 'of',\n",
       " 'you',\n",
       " 'right',\n",
       " 'now',\n",
       " 'chatiado',\n",
       " 'celebrate',\n",
       " 'every',\n",
       " 'man',\n",
       " 'that',\n",
       " 'have',\n",
       " 'play',\n",
       " 'it',\n",
       " 'have',\n",
       " 'it',\n",
       " 'be',\n",
       " 'fatherly',\n",
       " 'role',\n",
       " 'father',\n",
       " 'day',\n",
       " 'be',\n",
       " 'sure',\n",
       " 'they',\n",
       " 'be',\n",
       " 'just',\n",
       " 'as',\n",
       " 'happy',\n",
       " 'hour',\n",
       " 'the',\n",
       " 'white',\n",
       " 'establishment',\n",
       " 'can',\n",
       " 'not',\n",
       " 'have',\n",
       " 'blk',\n",
       " 'folx',\n",
       " 'run',\n",
       " 'around',\n",
       " 'love',\n",
       " 'themselves',\n",
       " 'and',\n",
       " 'promote',\n",
       " 'our',\n",
       " 'greatness',\n",
       " 'good',\n",
       " 'morning',\n",
       " 'the',\n",
       " 'journey',\n",
       " 'begin',\n",
       " 'travel',\n",
       " 'yeah',\n",
       " 'thejourneybegins',\n",
       " 'hello',\n",
       " 'if',\n",
       " 'you',\n",
       " 'luv',\n",
       " 'hottweets',\n",
       " 'like',\n",
       " 'this',\n",
       " 'from',\n",
       " 'venusexchange',\n",
       " 'our',\n",
       " 'new',\n",
       " 'brochures',\n",
       " 'have',\n",
       " 'arrive',\n",
       " 'how',\n",
       " 'excite',\n",
       " 'aworks',\n",
       " 'solutions',\n",
       " 'so',\n",
       " 'much',\n",
       " 'stuff',\n",
       " 'happen',\n",
       " 'in',\n",
       " 'florida',\n",
       " 'first',\n",
       " 'orlando',\n",
       " 'shoot',\n",
       " 'and',\n",
       " 'now',\n",
       " 'disneygatorattack',\n",
       " 'on',\n",
       " 'two',\n",
       " 'year',\n",
       " 'old',\n",
       " 'kid',\n",
       " 'ferrari',\n",
       " 'will',\n",
       " 'do',\n",
       " 'it',\n",
       " 'for',\n",
       " 'the',\n",
       " 'sake',\n",
       " 'of',\n",
       " 'the',\n",
       " 'championship',\n",
       " 'this',\n",
       " 'gp',\n",
       " 'be',\n",
       " 'clearly',\n",
       " 'turn',\n",
       " 'point',\n",
       " 'rb',\n",
       " 'ferrari',\n",
       " 'mercs',\n",
       " 'ace',\n",
       " 'my',\n",
       " 'first',\n",
       " 'test',\n",
       " 'proud',\n",
       " 'seek',\n",
       " 'probe',\n",
       " 'into',\n",
       " 'udtapunjab',\n",
       " 'leak',\n",
       " 'point',\n",
       " 'finger',\n",
       " 'at',\n",
       " 'amarinder',\n",
       " 'aap',\n",
       " 'wrap',\n",
       " 'up',\n",
       " 'senseaboutmaths',\n",
       " 'th',\n",
       " 'hey',\n",
       " 'white',\n",
       " 'people',\n",
       " 'you',\n",
       " 'can',\n",
       " 'call',\n",
       " 'people',\n",
       " 'white',\n",
       " 'by',\n",
       " 'race',\n",
       " 'identity',\n",
       " 'med',\n",
       " 'you',\n",
       " 'might',\n",
       " 'be',\n",
       " 'just',\n",
       " 'have',\n",
       " 'not',\n",
       " 'show',\n",
       " 'here',\n",
       " 'today',\n",
       " 'regurgitate',\n",
       " 'talk',\n",
       " 'point',\n",
       " 'and',\n",
       " 'name',\n",
       " 'call',\n",
       " 'sometimes',\n",
       " 'you',\n",
       " 'have',\n",
       " 'to',\n",
       " 'raise',\n",
       " 'few',\n",
       " 'brows',\n",
       " 'to',\n",
       " 'raise',\n",
       " 'the',\n",
       " 'bar',\n",
       " 'golfstrengthandconditioning',\n",
       " 'strong',\n",
       " 'felixfoisgolf',\n",
       " 'about',\n",
       " 'that',\n",
       " 'greathonour',\n",
       " 'careerconvos',\n",
       " 'design',\n",
       " 'innovative',\n",
       " 'learn',\n",
       " 'space',\n",
       " 'to',\n",
       " 'include',\n",
       " 'wateringhole',\n",
       " 'cave',\n",
       " 'mountaintop',\n",
       " 'campfire',\n",
       " 'how',\n",
       " 'the',\n",
       " 'altright',\n",
       " 'use',\n",
       " 'insecurity',\n",
       " 'to',\n",
       " 'lure',\n",
       " 'men',\n",
       " 'into',\n",
       " 'whitesupremacy',\n",
       " 'carry',\n",
       " 'gun',\n",
       " 'would',\n",
       " 'not',\n",
       " 'of',\n",
       " 'help',\n",
       " 'if',\n",
       " 'you',\n",
       " 'can',\n",
       " 'not',\n",
       " 'take',\n",
       " 'it',\n",
       " 'in',\n",
       " 'with',\n",
       " 'you',\n",
       " 'gun',\n",
       " 'control',\n",
       " 'will',\n",
       " 'not',\n",
       " 'stop',\n",
       " 'the',\n",
       " 'black',\n",
       " 'market',\n",
       " 'terrorism',\n",
       " 'will',\n",
       " 'get',\n",
       " 'worse',\n",
       " 'use',\n",
       " 'the',\n",
       " 'power',\n",
       " 'of',\n",
       " 'your',\n",
       " 'mind',\n",
       " 'to',\n",
       " 'heal',\n",
       " 'your',\n",
       " 'body',\n",
       " 'altwaystoheal',\n",
       " 'healthy',\n",
       " 'peace',\n",
       " 'woohoo',\n",
       " 'just',\n",
       " 'over',\n",
       " 'weeks',\n",
       " 'to',\n",
       " 'go',\n",
       " 'be',\n",
       " 'in',\n",
       " 'far',\n",
       " 'away',\n",
       " 'place',\n",
       " 'where',\n",
       " 'you',\n",
       " 'have',\n",
       " 'no',\n",
       " 'family',\n",
       " 'members',\n",
       " 'hus',\n",
       " 'ready',\n",
       " 'to',\n",
       " 'rehearse',\n",
       " 'tonight',\n",
       " 'with',\n",
       " 'new',\n",
       " 'music',\n",
       " 'and',\n",
       " 'new',\n",
       " 'videos',\n",
       " 'look',\n",
       " 'out',\n",
       " 'for',\n",
       " 'the',\n",
       " 'announcement',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_lemmatized = listmerge(list(combine_df['tweet_lemmatized']))\n",
    "corpus_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d15a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f649bd0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actual</th>\n",
       "      <th>ad</th>\n",
       "      <th>adapt</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586321</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586322</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586323</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586324</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586325</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>586326 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        abl  absolut  accept  account  act  action  actor  actual  ad  adapt  \\\n",
       "0         0        0       0        0    0       0      0       0   0      0   \n",
       "1         0        0       0        0    0       0      0       0   0      0   \n",
       "2         0        0       0        0    0       0      0       0   0      0   \n",
       "3         0        0       0        0    0       0      0       0   0      0   \n",
       "4         0        0       0        0    0       0      0       0   0      0   \n",
       "...     ...      ...     ...      ...  ...     ...    ...     ...  ..    ...   \n",
       "586321    0        0       0        0    0       0      0       0   0      0   \n",
       "586322    0        0       0        0    0       0      0       0   0      0   \n",
       "586323    0        0       0        0    0       0      0       0   0      0   \n",
       "586324    0        0       0        0    0       0      0       0   0      0   \n",
       "586325    0        0       0        0    0       0      0       0   0      0   \n",
       "\n",
       "        ...  yeah  year  yesterday  yo  yoga  york  young  youtub  yr  yummi  \n",
       "0       ...     0     0          0   0     0     0      0       0   0      0  \n",
       "1       ...     0     0          0   0     0     0      0       0   0      0  \n",
       "2       ...     0     0          0   0     0     0      0       0   0      0  \n",
       "3       ...     0     0          0   0     0     0      0       0   0      0  \n",
       "4       ...     0     0          0   0     0     0      0       0   0      0  \n",
       "...     ...   ...   ...        ...  ..   ...   ...    ...     ...  ..    ...  \n",
       "586321  ...     0     0          0   0     0     0      0       0   0      0  \n",
       "586322  ...     0     0          0   0     0     0      0       0   0      0  \n",
       "586323  ...     0     0          0   0     0     0      0       0   0      0  \n",
       "586324  ...     0     0          0   0     0     0      0       0   0      0  \n",
       "586325  ...     0     0          0   0     0     0      0       0   0      0  \n",
       "\n",
       "[586326 rows x 1000 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(\n",
    "    ngram_range=(1, 1), \n",
    "    analyzer='word', \n",
    "    binary=False,  \n",
    "    max_df=0.9,\n",
    "    max_features=1000, \n",
    "    stop_words='english',\n",
    ")\n",
    "\n",
    "# Создаем the Bag-of-Words модель\n",
    "bag_of_words = count_vectorizer.fit_transform(corpus_stemmed)\n",
    "\n",
    "# Отобразим Bag-of-Words модель как DataFrame\n",
    "feature_names = count_vectorizer.get_feature_names()\n",
    "\n",
    "count_vectorizer_stemmed = pd.DataFrame(bag_of_words.toarray(), columns = feature_names)\n",
    "vectorizers['count_vectorizer_stemmed'] = {'vectorizer': count_vectorizer, 'df': count_vectorizer_stemmed}\n",
    "count_vectorizer_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b7daeba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actually</th>\n",
       "      <th>adapt</th>\n",
       "      <th>add</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>yrs</th>\n",
       "      <th>yummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586321</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586322</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586323</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586324</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586325</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>586326 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        able  absolutely  accept  account  act  action  actor  actually  \\\n",
       "0          0           0       0        0    0       0      0         0   \n",
       "1          0           0       0        0    0       0      0         0   \n",
       "2          0           0       0        0    0       0      0         0   \n",
       "3          0           0       0        0    0       0      0         0   \n",
       "4          0           0       0        0    0       0      0         0   \n",
       "...      ...         ...     ...      ...  ...     ...    ...       ...   \n",
       "586321     0           0       0        0    0       0      0         0   \n",
       "586322     0           0       0        0    0       0      0         0   \n",
       "586323     0           0       0        0    0       0      0         0   \n",
       "586324     0           0       0        0    0       0      0         0   \n",
       "586325     0           0       0        0    0       0      0         0   \n",
       "\n",
       "        adapt  add  ...  yesterday  yo  yoga  york  young  youth  youtube  yr  \\\n",
       "0           0    0  ...          0   0     0     0      0      0        0   0   \n",
       "1           0    0  ...          0   0     0     0      0      0        0   0   \n",
       "2           0    0  ...          0   0     0     0      0      0        0   0   \n",
       "3           0    0  ...          0   0     0     0      0      0        0   0   \n",
       "4           0    0  ...          0   0     0     0      0      0        0   0   \n",
       "...       ...  ...  ...        ...  ..   ...   ...    ...    ...      ...  ..   \n",
       "586321      0    0  ...          0   0     0     0      0      0        0   0   \n",
       "586322      0    0  ...          0   0     0     0      0      0        0   0   \n",
       "586323      0    0  ...          0   0     0     0      0      0        0   0   \n",
       "586324      0    0  ...          0   0     0     0      0      0        0   0   \n",
       "586325      0    0  ...          0   0     0     0      0      0        0   0   \n",
       "\n",
       "        yrs  yummy  \n",
       "0         0      0  \n",
       "1         0      0  \n",
       "2         0      0  \n",
       "3         0      0  \n",
       "4         0      0  \n",
       "...     ...    ...  \n",
       "586321    0      0  \n",
       "586322    0      0  \n",
       "586323    0      0  \n",
       "586324    0      0  \n",
       "586325    0      0  \n",
       "\n",
       "[586326 rows x 1000 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(\n",
    "    ngram_range=(1, 1), \n",
    "    analyzer='word', \n",
    "    binary=False,  \n",
    "    max_df=0.9,\n",
    "    max_features=1000, \n",
    "    stop_words='english',\n",
    ")\n",
    "\n",
    "# Создаем the Bag-of-Words модель\n",
    "bag_of_words = count_vectorizer.fit_transform(corpus_lemmatized)\n",
    "\n",
    "# Отобразим Bag-of-Words модель как DataFrame\n",
    "feature_names = count_vectorizer.get_feature_names()\n",
    "\n",
    "count_vectorizer_lemmatized = pd.DataFrame(bag_of_words.toarray(), columns = feature_names)\n",
    "vectorizers['count_vectorizer_lemmatized'] = {'vectorizer': count_vectorizer, 'df': count_vectorizer_lemmatized}\n",
    "count_vectorizer_lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb427c9",
   "metadata": {},
   "source": [
    "2. Создайте мешок слов с помощью\n",
    "sklearn.feature_extraction.text.TfidfVectorizer.fit_transform(). Применим его к 'tweet_stemmed' и\n",
    "'tweet_lemmatized' отдельно.\n",
    "\n",
    "● Игнорируем слова, частота которых в документе строго превышает порог 0.9 с\n",
    "помощью max_df.\n",
    "\n",
    "● Ограничим количество слов, попадающий в мешок, с помощью max_features =\n",
    "1000.\n",
    "\n",
    "● Исключим стоп-слова с помощью stop_words='english'.\n",
    "\n",
    "● Отобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с\n",
    "помощью TfidfVectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7daefa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actual</th>\n",
       "      <th>ad</th>\n",
       "      <th>adapt</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586321</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586322</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586323</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586324</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586325</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>586326 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        abl  absolut  accept  account  act  action  actor  actual   ad  adapt  \\\n",
       "0       0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "1       0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "2       0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "3       0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "4       0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "...     ...      ...     ...      ...  ...     ...    ...     ...  ...    ...   \n",
       "586321  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "586322  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "586323  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "586324  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "586325  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "\n",
       "        ...  yeah  year  yesterday   yo  yoga  york  young  youtub   yr  yummi  \n",
       "0       ...   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "1       ...   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "2       ...   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "3       ...   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "4       ...   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "...     ...   ...   ...        ...  ...   ...   ...    ...     ...  ...    ...  \n",
       "586321  ...   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "586322  ...   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "586323  ...   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "586324  ...   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "586325  ...   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "\n",
       "[586326 rows x 1000 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 1), \n",
    "    analyzer='word', \n",
    "    binary=False,  \n",
    "    max_df=0.9,\n",
    "    max_features=1000, \n",
    "    stop_words='english',\n",
    ")\n",
    "\n",
    "# Создаем the Bag-of-Words модель\n",
    "values = tfidf_vectorizer.fit_transform(corpus_stemmed)\n",
    "\n",
    "# Отобразим Bag-of-Words модель как DataFrame\n",
    "feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "tfidf_vectorizer_stemmed = pd.DataFrame(values.toarray(), columns = feature_names)\n",
    "vectorizers['tfidf_vectorizer_stemmed'] = {'vectorizer': tfidf_vectorizer, 'df': tfidf_vectorizer_stemmed}\n",
    "tfidf_vectorizer_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d69e6271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actually</th>\n",
       "      <th>adapt</th>\n",
       "      <th>add</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>yrs</th>\n",
       "      <th>yummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586321</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586322</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586323</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586324</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586325</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>586326 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        able  absolutely  accept  account  act  action  actor  actually  \\\n",
       "0        0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0   \n",
       "1        0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0   \n",
       "2        0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0   \n",
       "3        0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0   \n",
       "4        0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0   \n",
       "...      ...         ...     ...      ...  ...     ...    ...       ...   \n",
       "586321   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0   \n",
       "586322   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0   \n",
       "586323   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0   \n",
       "586324   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0   \n",
       "586325   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0   \n",
       "\n",
       "        adapt  add  ...  yesterday   yo  yoga  york  young  youth  youtube  \\\n",
       "0         0.0  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0   \n",
       "1         0.0  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0   \n",
       "2         0.0  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0   \n",
       "3         0.0  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0   \n",
       "4         0.0  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0   \n",
       "...       ...  ...  ...        ...  ...   ...   ...    ...    ...      ...   \n",
       "586321    0.0  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0   \n",
       "586322    0.0  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0   \n",
       "586323    0.0  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0   \n",
       "586324    0.0  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0   \n",
       "586325    0.0  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0   \n",
       "\n",
       "         yr  yrs  yummy  \n",
       "0       0.0  0.0    0.0  \n",
       "1       0.0  0.0    0.0  \n",
       "2       0.0  0.0    0.0  \n",
       "3       0.0  0.0    0.0  \n",
       "4       0.0  0.0    0.0  \n",
       "...     ...  ...    ...  \n",
       "586321  0.0  0.0    0.0  \n",
       "586322  0.0  0.0    0.0  \n",
       "586323  0.0  0.0    0.0  \n",
       "586324  0.0  0.0    0.0  \n",
       "586325  0.0  0.0    0.0  \n",
       "\n",
       "[586326 rows x 1000 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 1), \n",
    "    analyzer='word', \n",
    "    binary=False,  \n",
    "    max_df=0.9,\n",
    "    max_features=1000, \n",
    "    stop_words='english',\n",
    ")\n",
    "\n",
    "# Создаем the Bag-of-Words модель\n",
    "values = tfidf_vectorizer.fit_transform(corpus_lemmatized)\n",
    "\n",
    "# Отобразим Bag-of-Words модель как DataFrame\n",
    "feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "tfidf_vectorizer_lemmatized = pd.DataFrame(values.toarray(), columns = feature_names)\n",
    "vectorizers['tfidf_vectorizer_lemmatized'] = {'vectorizer': tfidf_vectorizer, 'df': tfidf_vectorizer_lemmatized}\n",
    "tfidf_vectorizer_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4773079c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count_vectorizer_stemmed</th>\n",
       "      <td>CountVectorizer(max_df=0.9, max_features=1000,...</td>\n",
       "      <td>abl  absolut  accept  account  act  ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_vectorizer_lemmatized</th>\n",
       "      <td>CountVectorizer(max_df=0.9, max_features=1000,...</td>\n",
       "      <td>able  absolutely  accept  account  act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_vectorizer_stemmed</th>\n",
       "      <td>TfidfVectorizer(max_df=0.9, max_features=1000,...</td>\n",
       "      <td>abl  absolut  accept  account  act  ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_vectorizer_lemmatized</th>\n",
       "      <td>TfidfVectorizer(max_df=0.9, max_features=1000,...</td>\n",
       "      <td>able  absolutely  accept  account  act...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    vectorizer  \\\n",
       "count_vectorizer_stemmed     CountVectorizer(max_df=0.9, max_features=1000,...   \n",
       "count_vectorizer_lemmatized  CountVectorizer(max_df=0.9, max_features=1000,...   \n",
       "tfidf_vectorizer_stemmed     TfidfVectorizer(max_df=0.9, max_features=1000,...   \n",
       "tfidf_vectorizer_lemmatized  TfidfVectorizer(max_df=0.9, max_features=1000,...   \n",
       "\n",
       "                                                                            df  \n",
       "count_vectorizer_stemmed             abl  absolut  accept  account  act  ac...  \n",
       "count_vectorizer_lemmatized          able  absolutely  accept  account  act...  \n",
       "tfidf_vectorizer_stemmed             abl  absolut  accept  account  act  ac...  \n",
       "tfidf_vectorizer_lemmatized          able  absolutely  accept  account  act...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vectorizers = pd.DataFrame(vectorizers).T\n",
    "df_vectorizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33df8e54",
   "metadata": {},
   "source": [
    "3. Проверьте ваши векторайзеры на корпусе который использовали на вебинаре, составьте\n",
    "таблицу метод векторизации и скор который вы получили (в методах векторизации по\n",
    "изменяйте параметры что бы добиться лучшего скора) обратите внимание как\n",
    "падает/растёт скор при уменьшении количества фичей, и изменении параметров, так же"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efe03ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       label\n",
       "0  Stuning even for the non-gamer: This sound tra...  __label__2\n",
       "1  The best soundtrack ever to anything.: I'm rea...  __label__2\n",
       "2  Amazing!: This soundtrack is my favorite music...  __label__2\n",
       "3  Excellent Soundtrack: I truly like this soundt...  __label__2\n",
       "4  Remember, Pull Your Jaw Off The Floor After He...  __label__2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загружаем данные\n",
    "data = open('corpus').read()\n",
    "labels, texts = [], []\n",
    "for i, line in enumerate(data.split(\"\\n\")):\n",
    "    content = line.split()\n",
    "    labels.append(content[0])\n",
    "    texts.append(\" \".join(content[1:]))\n",
    "\n",
    "# создаем df\n",
    "trainDF = pd.DataFrame()\n",
    "trainDF['text'] = texts\n",
    "trainDF['label'] = labels\n",
    "trainDF.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c7889f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['label'])\n",
    "# labelEncode целевую переменную\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.transform(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ca90b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, vectorizer in zip(df_vectorizers.index, df_vectorizers['vectorizer']):\n",
    "    xtrain_count =  vectorizer.transform(train_x)\n",
    "    xvalid_count =  vectorizer.transform(valid_x)\n",
    "\n",
    "    classifier = linear_model.LogisticRegression()\n",
    "    classifier.fit(xtrain_count, train_y)\n",
    "    predictions = classifier.predict(xvalid_count)\n",
    "    acc = accuracy_score(valid_y, predictions)\n",
    "    \n",
    "    vectorizers[name]['accuracy'] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd17ea43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>df</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count_vectorizer_stemmed</th>\n",
       "      <td>CountVectorizer(max_df=0.9, max_features=1000,...</td>\n",
       "      <td>abl  absolut  accept  account  act  ac...</td>\n",
       "      <td>0.7368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_vectorizer_lemmatized</th>\n",
       "      <td>CountVectorizer(max_df=0.9, max_features=1000,...</td>\n",
       "      <td>able  absolutely  accept  account  act...</td>\n",
       "      <td>0.7668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_vectorizer_stemmed</th>\n",
       "      <td>TfidfVectorizer(max_df=0.9, max_features=1000,...</td>\n",
       "      <td>abl  absolut  accept  account  act  ac...</td>\n",
       "      <td>0.7428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_vectorizer_lemmatized</th>\n",
       "      <td>TfidfVectorizer(max_df=0.9, max_features=1000,...</td>\n",
       "      <td>able  absolutely  accept  account  act...</td>\n",
       "      <td>0.7716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    vectorizer  \\\n",
       "count_vectorizer_stemmed     CountVectorizer(max_df=0.9, max_features=1000,...   \n",
       "count_vectorizer_lemmatized  CountVectorizer(max_df=0.9, max_features=1000,...   \n",
       "tfidf_vectorizer_stemmed     TfidfVectorizer(max_df=0.9, max_features=1000,...   \n",
       "tfidf_vectorizer_lemmatized  TfidfVectorizer(max_df=0.9, max_features=1000,...   \n",
       "\n",
       "                                                                            df  \\\n",
       "count_vectorizer_stemmed             abl  absolut  accept  account  act  ac...   \n",
       "count_vectorizer_lemmatized          able  absolutely  accept  account  act...   \n",
       "tfidf_vectorizer_stemmed             abl  absolut  accept  account  act  ac...   \n",
       "tfidf_vectorizer_lemmatized          able  absolutely  accept  account  act...   \n",
       "\n",
       "                            accuracy  \n",
       "count_vectorizer_stemmed      0.7368  \n",
       "count_vectorizer_lemmatized   0.7668  \n",
       "tfidf_vectorizer_stemmed      0.7428  \n",
       "tfidf_vectorizer_lemmatized   0.7716  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vectorizers = pd.DataFrame(vectorizers).T\n",
    "df_vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4fe5c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfidf_vectorizer_lemmatized    0.7716\n",
       "count_vectorizer_lemmatized    0.7668\n",
       "tfidf_vectorizer_stemmed       0.7428\n",
       "count_vectorizer_stemmed       0.7368\n",
       "Name: accuracy, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vectorizers['accuracy'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd82591e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
